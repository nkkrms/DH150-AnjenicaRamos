# Assignment02: User Testing
##### Anjenica (Nikki) Ramos
##### DH 150: User Experience Design, Spring 2020 - Prof. Cho

#### Working Interest: Coronavirus Resource Site Improvement

#### Purpose of UT 
-Introduction with the name of the web/app you test and what the web/app is about. 
-Report the rationale behind of UT with the list of the usability issues you found from your heuristic reviews
-Indicate that the purpose of the usability testing aims to find out how to improve the web/app from the user's perspective.

The World Health Organization is a trusted international health agency which coordinates health efforts within countries of the United Nations, and, thus, currently serves as a leading source towards COVID-19 initiatives. Their Coronavirus information website features factual basics, advice and resources for the public, as well as regularly updated regulations and statistics of the ongoing pandemic. 
In this assignment, I will be conducting a usability test to evaluate the site's interface in regards to goals of effectivity, efficiency, and satisfaction towards its purposes as a public resource. Though doing so, I will be able to observe the site in use through a participant's behavior, which can then provide insight towards improvement for the site. 
Here, I will specifically focus on areas of concern revealed by prior heuristic evaluation: (1) consistency and standards, (2) flexibility and efficiency of us, and (3) aesthetics and minimal design. At first glance, the WHO COVID-19 site does not appear to be problematic, though, exploration reveals various aspects of its design and structuring that hinders its purpose. Predominantly, the site has little standardization in terms of its information's organization, resulting in users ineffectively spending their time sifting through the text-heavy content to find the information they seek. This can lead to a bothersome ordeal and discourage use of the site overall. 
Through user testing, I aim to capture evidence of global problems from a user's perspective in over to support later design improvements and embetter overall user experience. 


#### Methodology
-Describe the setting(where, portable minimalistic lab), equipment(computer, software)
Describe the process (ex. Background questions, pretest, posttest) and what was measured (ex. Ease of use)
To do so, I will conduct a pilot test in a portable minimalistic lab (at home) as a moderator with a participant (my brother), in order to test the setting, materials, and software involved in this process. I will use my personal laptop with internet connection to access the site in question, Apowersoft Online Screen Recorder to capture the testing session, and Google Forms to host the formal evaluation.  
I, as the moderator, will introduce the project and usability testing procedure to the participant. After consenting to the session, I will lead the participant through background, pre-test, task, and post-test questions. During this, the participant will fill out the online form evaluation and talk aloud their thinking process. First, we will capture their first impressions of the site UI prior to any interactions. Then, they will complete four (revised from the original three) tasks designed to highlight the site's problem areas and capture natural troubleshooting by the user. This is meant to test the general functionality of the site. Next, the user will be able to share their opinons of their experience, in addition to the site's effectivity, efficiency, and satisfaction factors. Finally, we will collect demographic data. 


[Online Survey]() 
The link to your online survey (UT materials), share the survey with the instructor

[Pilot UT]()
The link to your pilot UT video (e.g., youtube or google drive)

#### Reflection:
One paragraph describing what you learned during the pilot test, what went well and what went not so well, focusing on how you want to improve your UT in the future.

In terms of what the user testing has revealed, there are definite issues with the irregular, and therefore, unpredictable nature, of the WHO COVID-19 site's interface. The format of how information itself, as well as links/buttons, varied page to page, resulting in the participant to spend much of their time scanning and scrolling to find the information. To me, I considered this a matter of inconsistency, but, as by participant/brother expressed after the formal session/recording ended, he thought it was also a matter of being *too* consistent -- in that he repeatedly looked passed things because they were not obvious enough or "jumped out" at him to draw his attention. This shifted my perspective to make sure I focus on standardizing certain elements to the site, while creating clearer information hierarchies and eye-catching displays (or use of icons/symbols?) elsewhere. In relation, it was also made clear that the site was text-heavy (paragraphs > bulletpoints, articles > infographics), such that it was ironic that pieces of critical information was time-consuming to locate. 

This overall covers the success of the UT session, as the testing definitely reveals insights that I can utilize for eventual designs. In addition, I took the route of tailoring portions of the Google Form evaluation provided to add an additional task and expand upon the word-card portion of the post-test. I believe this was beneficial in pointing out additional site problems and enabled me to receive more feedback of user experience, especially with only one participant. Some aspects of the users behavior (ex. actually reading through everything instead of immediately resulting to CTRL-F to find something) and opinon (ex. the aformentioned over-consistency) were not expected, but definitely expanded my own thinking. 

In relation to conducting the user testing itself, I definitely realize the difference in my perspective as the moderator/tester, as someone who has scowered through the site much more in depth. This definitely attests to gaining empathy towards participants, as the Prof. pointed out within the lecture, because there can be points of frustration and confusion throughout their experience. 

The portions which did not go so well generally regard this first experience of mine fascilitating this process. First off, I did find some typos in my form that I missed despite revising it 2x. Secondly, I realized that I had designed each task of the testing portion independently of eachother and with starting at the home page in mind - I instinctively led the participant to go back to the starting page and remembered immediately after that I am not supposed to intervene. 

However, aside that, it was in taking *active* charge of my role I require improvement on: I had to recall that I am supposed to read certain aloud segments of questionnaire and manage the pacing of it, as opposed to letting the participant do so. (I believe this was partly because they were aware they had to talk though their thinking, and so they naturally spoke what they read as well). 


What went well
- tasks revealed various problems in the site 
- text-heavy, lack of hierarchy, too many clicks to find things

Not went so well
- typos
- first time moderating: taking charge of the session
- interrupting: 
I realized I designed each task with starting at the homepage in mind, and instinctively led the participant to go back to the starting page and remembered immediately after that I am not supposed to intervene. 

How I want to improve my user 
